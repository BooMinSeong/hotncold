# Hot and Cold Temperature - ë‹¤ìŒ í™•ì¥ ê³„íš

## í˜„ì¬ êµ¬í˜„ ìƒíƒœ (Phase 1 - ì™„ë£Œ)

âœ… **best_of_n ì•Œê³ ë¦¬ì¦˜ Multi-Temperature ì§€ì›**
- Helper í•¨ìˆ˜: `src/sal/utils/temperature.py`
- Config í™•ì¥: `temperatures`, `temperature_ratios` í•„ë“œ
- SamplingParams ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•œ êµ¬í˜„
- ê· ë“± ë¶„ë°° ë° ì‚¬ìš©ì ì§€ì • ë¹„ìœ¨ ì§€ì›

## Phase 2: beam_search í™•ì¥

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

**ê¸°ì¡´ ë°©ì‹ì˜ ë¬¸ì œì **:
- ê° beamì— í•˜ë‚˜ì˜ temperatureë¥¼ í• ë‹¹í•˜ë©´, beamì´ pruningë  ë•Œ í•´ë‹¹ temperatureê°€ ì‚¬ë¼ì ¸ search spaceê°€ ì œí•œë¨

**ìƒˆë¡œìš´ ì ‘ê·¼**:
- ê° beamì´ ë§¤ iterationë§ˆë‹¤ temperature_list ë¹„ìœ¨ëŒ€ë¡œ ì—¬ëŸ¬ next_textë¥¼ ìƒì„±
- **ê³ ì •ê°’ ì‚¬ìš©**: `continuations_per_beam = config.n // config.beam_width`
- ì˜ˆ: n=16, beam_width=4 â†’ ê° beamë‹¹ í•­ìƒ 4ê°œì˜ next_text
  - temperature_list=[0.6, 0.8, 1.0], temperature_ratios=[1,1,1]
  - ê° beamì˜ next_texts: 1ê°œ(T=0.6) + 2ê°œ(T=0.8) + 1ê°œ(T=1.0) = 4ê°œ
- ê° beamì˜ next_texts ì¤‘ PRM ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ê²ƒì„ ì„ íƒ

**ì¥ì **:
- Beamì´ pruningë˜ì–´ë„ ì‚´ì•„ìˆëŠ” beamë“¤ì´ ëª¨ë“  temperature ìœ ì§€
- active_beamsê°€ ì¤„ë©´ ì´ computationë„ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì†Œ
- best_of_nê³¼ ë™ì¼í•œ temperature ë¶„ë°° ë©”ì»¤ë‹ˆì¦˜ ì¬ì‚¬ìš©

### í•„ìš”í•œ ë³€ê²½ì‚¬í•­

1. **generate_k_steps ì œê±° ë° ì§ì ‘ generation** (`beam_search.py`):

   **ì´ìœ **:
   - lookahead ë¶ˆí•„ìš” (temperature ë‹¤ì–‘ì„±ìœ¼ë¡œ ëŒ€ì²´)
   - ê° beamë§ˆë‹¤ ë‹¤ë¥¸ temperature ë¦¬ìŠ¤íŠ¸ ì ìš©í•˜ê¸° ìœ„í•¨
   - ì½”ë“œ ë‹¨ìˆœí™”

   ```python
   # ê° beamë‹¹ next_text ê°œìˆ˜ (ê³ ì •ê°’)
   continuations_per_beam = config.n // config.beam_width

   # temperature_list ë¹„ìœ¨ëŒ€ë¡œ ë¶„ë°°
   from sal.utils.temperature import get_temperature_assignment
   temp_config = copy.copy(config)
   temp_config.n = continuations_per_beam
   temps = get_temperature_assignment(temp_config)

   # ê° beamë§ˆë‹¤ temperatureë³„ë¡œ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
   prompts = []
   sampling_params_list = []

   for beam in active_beams:
       conv = build_conv(beam.prompt, beam.current_text, config.system_prompt)
       templated_conv = tokenizer.apply_chat_template(
           conv,
           add_generation_prompt=(i == 0),
           continue_final_message=(i > 0),
           tokenize=False
       )

       for t in temps:
           prompts.append(templated_conv)
           is_last_iteration = (i == config.num_iterations - 1)
           sampling_params_list.append(
               SamplingParams(
                   temperature=t,
                   max_tokens=config.max_tokens,
                   top_p=config.top_p,
                   stop=["\n\n"] if not is_last_iteration else None,
                   include_stop_str_in_output=True,
                   n=1
               )
           )

   # vLLM ì§ì ‘ í˜¸ì¶œ
   outputs = llm.generate(prompts, sampling_params_list, use_tqdm=False)
   ```

2. **Beamë³„ next_texts í• ë‹¹**:

   ```python
   # outputsë¥¼ beamë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ next_textsì— í• ë‹¹
   # ì´ len(active_beams) * continuations_per_beam ê°œì˜ output

   for beam_idx, beam in enumerate(active_beams):
       start_idx = beam_idx * continuations_per_beam
       end_idx = start_idx + continuations_per_beam
       beam_outputs = outputs[start_idx:end_idx]

       # Beam í´ë˜ìŠ¤ì˜ ê¸°ì¡´ í•„ë“œì— ì €ì¥
       beam.next_texts = [out.outputs[0].text for out in beam_outputs]
       beam.stop_reasons = [out.outputs[0].finish_reason for out in beam_outputs]
       beam.completion_tokens += sum(len(out.outputs[0].token_ids) for out in beam_outputs)
   ```

3. **PRM Scoring** (ê¸°ì¡´ ë°©ì‹ ìœ ì§€):

   ```python
   # ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ PRM scoring
   prompts, completions = [], []

   for beam in active_beams:
       for next_text in beam.next_texts:
           prompts.append(beam.prompt)
           completions.append([beam.current_text + next_text])

   scores = prm.score(prompts, completions)
   ```

4. **ê° Beamì˜ ìµœê³ ì  next_text ì„ íƒ ë° ì ìš©**:

   ```python
   # ê° beamë§ˆë‹¤ ìµœê³ ì ë§Œ ì„ íƒí•˜ì—¬ current_textì— ë°˜ì˜
   score_idx = 0
   for beam in active_beams:
       beam_scores = []
       for _ in beam.next_texts:
           agg_score = aggregate_scores(scores[score_idx][0], config.agg_strategy)
           beam_scores.append(agg_score)
           score_idx += 1

       # ìµœê³ ì  ì„ íƒ
       best_idx = np.argmax(beam_scores)

       # Beamì— ìµœê³ ì  ì ìš©
       beam.current_text += beam.next_texts[best_idx]
       beam.history.append(beam.next_texts[best_idx])
       beam.all_scores = scores[beam_idx * continuations_per_beam + best_idx][0]

       # ì™„ë£Œ ì²´í¬
       if beam.stop_reasons[best_idx] in ["stop", "length"] or beam.next_texts[best_idx] == "":
           beam.completed = True
           completed_beams.append(beam)
   ```

5. **Beam Pruning** (ê¸°ì¡´ ë°©ì‹ ìœ ì§€):

   ```python
   # ì™„ë£Œëœ beam ì œê±°
   active_beams = [b for b in active_beams if not b.completed]

   # ì¤‘ë³µ ì œê±° (config.filter_duplicates)
   # ...ê¸°ì¡´ ë¡œì§ ìœ ì§€...

   # ê° beamì˜ ìµœì¢… ìŠ¤ì½”ì–´ë¡œ top k ì„ íƒ
   agg_scores = [aggregate_scores(b.all_scores, config.agg_strategy) for b in active_beams]
   top_indices = np.argsort(agg_scores)[-(config.n // config.beam_width):]

   for idx, beam in enumerate(active_beams):
       if idx not in top_indices:
           beam.pruned = True
   ```

### ë³€ê²½ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„

- **Beam í´ë˜ìŠ¤**: ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì‚¬ìš© (next_textsëŠ” ì´ë¯¸ list[str])
- **PRM scoring ì•Œê³ ë¦¬ì¦˜**: ë™ì¼
- **Pruning ë¡œì§**: ë™ì¼
- **ì™„ë£Œ ì²˜ë¦¬**: ë™ì¼

### í•µì‹¬ ê°œë…

- **Beamì€ temperatureë¥¼ ì†Œìœ í•˜ì§€ ì•ŠìŒ**
- ë§¤ iterationë§ˆë‹¤ ëª¨ë“  beamì´ ë™ì¼í•œ temperature ë¶„í¬ ì‚¬ìš©
- ê° beamì€ ì—¬ëŸ¬ next_texts ì¤‘ PRM ìµœê³ ì ë§Œ ì„ íƒ
- **ê³ ì •ëœ continuations_per_beamìœ¼ë¡œ computation budget ì œì–´**
- **lookahead ì œê±°** (temperature ë‹¤ì–‘ì„±ìœ¼ë¡œ ëŒ€ì²´)
- **generate_k_steps ì œê±°** (ì§ì ‘ llm.generate ì‚¬ìš©)
- best_of_nì˜ `get_temperature_assignment()` ë¡œì§ ì¬ì‚¬ìš©

### Computation Budget ì˜ˆì‹œ

- n=16, beam_width=4 â†’ search = n / beam_width = 4 (ê° beamë‹¹ continuation ê°œìˆ˜)
- ë§¤ iterationë§ˆë‹¤ active_beamsë¥¼ n=16ê°œë¡œ ìœ ì§€ (duplication, ê¸°ì¡´ê³¼ ë™ì¼)
- ê° beamë‹¹ search=4ê°œ continuation ìƒì„±
- ì´ 16Ã—4=64ê°œ generation per iteration
- PRMìœ¼ë¡œ ìŠ¤ì½”ì–´ë§ í›„ ê° beamì˜ ìµœê³ ì  ì„ íƒ
- Top n//beam_width=4ê°œ beam ì„ íƒ (pruning)

**í•µì‹¬**:
- ê¸°ì¡´ ì½”ë“œì˜ duplication/pruning ë¡œì§ ìœ ì§€
- ë³€ê²½: ê° beamë‹¹ 1ê°œ â†’ searchê°œ continuation ìƒì„±

### ì˜ˆìƒ êµ¬í˜„ ë‚œì´ë„

**ì¤‘ê°„**: generate_k_steps ì œê±°, ì§ì ‘ generation, beamë³„ ê·¸ë£¹í•‘ ë° ìµœê³ ì  ì„ íƒ ì¶”ê°€

## Phase 3: dvts í™•ì¥

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

**DVTS êµ¬ì¡°**:
- `n_beams`: ë©”ì¸ beam ê°œìˆ˜
- `beam_width`: ê° beamì˜ diverse path ê°œìˆ˜
- ê° ë©”ì¸ beamì´ beam_widthê°œì˜ ë‹¤ì–‘í•œ ê²½ë¡œë¥¼ ìœ ì§€

**Temperature ì ìš© ë°©ì‹ (beam_searchì™€ ìœ ì‚¬)**:
- ê° diverse pathê°€ temperature_list ë¹„ìœ¨ëŒ€ë¡œ ì—¬ëŸ¬ continuation ìƒì„±
- DVTSì˜ ê²½ìš° beam_widthê°€ ë‹¤ë¥¸ ì˜ë¯¸ì´ë¯€ë¡œ search ê³„ì‚° ë°©ì‹ í™•ì¸ í•„ìš”
- Diverse pathê°€ ì‚¬ë¼ì ¸ë„ ë‚¨ì€ pathë“¤ì´ ëª¨ë“  temperature ìœ ì§€

### í•„ìš”í•œ ë³€ê²½ì‚¬í•­

1. **Search ê°œìˆ˜ ê³„ì‚° ë° generate_k_steps ì œê±°**:
   ```python
   # DVTSì˜ ê²½ìš° config.nê³¼ beam_width ê´€ê³„ í™•ì¸ í•„ìš”
   # beam_search: search = config.n // config.beam_width
   # DVTS: search = ? (ì½”ë“œ ë¶„ì„ í›„ ê²°ì •)

   continuations_per_path = # DVTSì— ë§ëŠ” ê³„ì‚°ì‹

   from sal.utils.temperature import get_temperature_assignment
   temp_config = copy.copy(config)
   temp_config.n = continuations_per_path
   temps = get_temperature_assignment(temp_config)

   # ê° diverse pathë§ˆë‹¤ temperatureë³„ë¡œ ì—¬ëŸ¬ continuation ìƒì„±
   prompts = []
   sampling_params_list = []

   for beam in active_beams:
       for diverse_path_idx in range(beam_width):
           conv = build_conv(...)
           templated_conv = tokenizer.apply_chat_template(...)

           for t in temps:
               prompts.append(templated_conv)
               sampling_params_list.append(SamplingParams(temperature=t, ...))

   outputs = llm.generate(prompts, sampling_params_list, use_tqdm=False)
   ```

2. **PRM Scoring ë° ìµœê³ ì  ì„ íƒ** (beam_searchì™€ ë™ì¼ íŒ¨í„´):
   ```python
   # ê° diverse pathì˜ ì—¬ëŸ¬ continuation ì¤‘ PRM ìµœê³ ì  ì„ íƒ
   # beam_searchì˜ ë¡œì§ì„ diverse pathì— ì ìš©
   ```

3. **DVTS ê³ ìœ ì˜ Diversity/Verification ë¡œì§ ìœ ì§€**:
   - Diversity-based selection
   - Verification-based pruning
   - ê¸°ì¡´ DVTS ì•Œê³ ë¦¬ì¦˜ì€ ìœ ì§€, temperature ë¶€ë¶„ë§Œ í™•ì¥

### í•µì‹¬ ê°œë…

- **Beam/PathëŠ” temperatureë¥¼ ì†Œìœ í•˜ì§€ ì•ŠìŒ** (beam_searchì™€ ë™ì¼)
- ê° diverse pathê°€ ë™ì¼í•œ temperature ë¶„í¬ ì‚¬ìš©
- **lookahead ì œê±°, generate_k_steps ì œê±°** (beam_searchì™€ ë™ì¼)
- best_of_nì˜ `get_temperature_assignment()` ë¡œì§ ì¬ì‚¬ìš©

### ì˜ˆìƒ êµ¬í˜„ ë‚œì´ë„

**ë‚®ìŒ**: beam_search íŒ¨í„´ ê±°ì˜ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥ (DVTS íŠ¹ìœ ì˜ diverse path ì²˜ë¦¬ë§Œ ì¶”ê°€)

## êµ¬í˜„ ìˆœì„œ

1. âœ… Phase 1: best_of_n (ì™„ë£Œ)
2. ğŸ”œ Phase 2: beam_search
   - generate_k_steps ì œê±°
   - ì§ì ‘ llm.generate() í˜¸ì¶œë¡œ ë³€ê²½
   - ê° beamë‹¹ searchê°œ continuation ìƒì„± (temperatureë³„)
   - PRM ìŠ¤ì½”ì–´ë§ ë° ìµœê³ ì  ì„ íƒ
   - ê¸°ì¡´ duplication/pruning ë¡œì§ ìœ ì§€
   - í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
3. ğŸ”œ Phase 3: dvts
   - beam_search íŒ¨í„´ ì ìš©
   - DVTS êµ¬ì¡°ì— ë§ê²Œ search ê³„ì‚°
   - generate_k_steps ì œê±°
   - ê° diverse pathë‹¹ continuation ìƒì„± (temperatureë³„)
   - í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

## ì°¸ê³  ìë£Œ

- Plan íŒŒì¼: `/home/b.ms/.claude/plans/eager-stirring-cocoa.md`
- vLLM ë¬¸ì„œ: https://docs.vllm.ai/en/v0.6.4/dev/sampling_params.html
- í˜„ì¬ êµ¬í˜„ ì»¤ë°‹: [ì´ íŒŒì¼ê³¼ í•¨ê»˜ ì»¤ë°‹ë¨]
