<p align="center">
  <img style="width:200px" src="https://raw.githubusercontent.com/huggingface/search-and-learn/main/assets/logo.png">
</p>

<p align="center">
      ğŸ¤— <a href="https://huggingface.co/collections/HuggingFaceH4/scaling-test-time-compute-with-open-models-675c3b475a0d6eb4528fec23" target="_blank">Models & Datasets</a> |
      ğŸ“ƒ <a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute" target="_blank">Blog Post</a>
</p>

# hotncold: Temperature-Aware Test-Time Scaling

Test-time compute scalingì´ ê²°êµ­ **íƒìƒ‰(search)** ì˜ ë°˜ë³µì´ë¼ëŠ” ê´€ì ì—ì„œ, LLM ë””ì½”ë”©ì˜ í•µì‹¬ ë³€ìˆ˜ì¸ **ìƒ˜í”Œë§ ì˜¨ë„**ê°€ íƒìƒ‰ íš¨ìœ¨ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ì—°êµ¬ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

> *"The two methods that seem to scale arbitrarily are **search** and **learning**."*
> â€” Rich Sutton, [The Bitter Lesson](https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson.pdf)

---

## ì—°êµ¬ ë°°ê²½ ë° ê°€ì„¤

Test-time compute scaling(TTS)ì€ ëª¨ë¸ì´ í•˜ë‚˜ì˜ ë¬¸ì œì— ëŒ€í•´ Në²ˆì˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨, ì¶”ê°€ í•™ìŠµ ì—†ì´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë³¸ì§ˆì ìœ¼ë¡œ **í•´ ê³µê°„(solution space)ì„ ë°˜ë³µì ìœ¼ë¡œ íƒìƒ‰**í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.

ì´ë•Œ ìƒ˜í”Œë§ ì˜¨ë„ $T$ëŠ” íƒìƒ‰ ë²”ìœ„ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤:

| ì˜¨ë„ | íƒìƒ‰ íŠ¹ì„± | ì˜ˆìƒ ê°•ì  |
| :--- | :--- | :--- |
| **ì €ì˜¨ (Cold, $T \to 0$)** | ì¢ê³  ì§‘ì¤‘ëœ íƒìƒ‰ â€” ê³ í™•ë¥  ê²½ë¡œì— ìˆ˜ë ´ | ë‹¨ì¼ ì •ë‹µì´ ëª…í™•í•œ ë¬¸ì œ, ë…¼ë¦¬ê°€ ì—°ì‡„ì ì¸ ë¬¸ì œ |
| **ê³ ì˜¨ (Hot, $T \to 1+$)** | ë„“ê³  ë‹¤ì–‘í•œ íƒìƒ‰ â€” ì €í™•ë¥  ê²½ë¡œê¹Œì§€ íƒìƒ‰ | ì—¬ëŸ¬ ì ‘ê·¼ë²•ì´ ê°€ëŠ¥í•œ ë¬¸ì œ, ì°½ì˜ì  ì¶”ë¡ ì´ í•„ìš”í•œ ë¬¸ì œ |

**í•µì‹¬ ê°€ì„¤**: ë™ì¼í•œ ê³„ì‚° ì˜ˆì‚°(N) í•˜ì—ì„œ, ë¬¸ì œì˜ íŠ¹ì„±ì— ë”°ë¼ ìµœì  ìƒ˜í”Œë§ ì˜¨ë„ê°€ ë‹¤ë¥´ë©°, ì €ì˜¨ê³¼ ê³ ì˜¨ì˜ íƒìƒ‰ ë²”ìœ„ ì°¨ì´ê°€ ë¬¸ì œë³„ TTS íš¨ìœ¨ ì°¨ì´ë¥¼ ì„¤ëª…í•œë‹¤.

---

## ì ‘ê·¼ ë°©ë²•

ì„¸ ê°€ì§€ íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ PRM(Process Reward Model) ê¸°ë°˜ìœ¼ë¡œ ì˜¨ë„ë³„ íƒìƒ‰ íš¨ìœ¨ì„ ì¸¡ì •í•©ë‹ˆë‹¤:

| ì•Œê³ ë¦¬ì¦˜ | í•µì‹¬ ì•„ì´ë””ì–´ |
| :--- | :--- |
| **Best-of-N** | Nê°œ ì™„ì„±ë³¸ ìƒ˜í”Œë§ í›„ PRM ìµœê³  ì ìˆ˜ ì„ íƒ |
| **Beam Search** | ê° ì¶”ë¡  ë‹¨ê³„ì—ì„œ PRM ì ìˆ˜ë¡œ ë¹” í™•ì¥ |
| **DVTS** | ë‹¤ì–‘ì„±ê³¼ ê²€ì¦ì„ ê· í˜•ìˆê²Œ ê²°í•©í•œ íŠ¸ë¦¬ íƒìƒ‰ |

ì˜¨ë„ê°€ ê° ì•Œê³ ë¦¬ì¦˜ì˜ íƒìƒ‰ ë‹¤ì–‘ì„±ê³¼ ìˆ˜ë ´ ì†ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¹„êµí•¨ìœ¼ë¡œì¨, **"ì–¸ì œ hotì´ coldë³´ë‹¤ ìœ ë¦¬í•œê°€"** ë¥¼ ê·œëª…í•©ë‹ˆë‹¤.

---

## ì„¤ì¹˜

```shell
conda create -n sal python=3.11 && conda activate sal
pip install -e '.[dev]'
huggingface-cli login
```

---

## ë¹ ë¥¸ ì‹œì‘

```shell
export CONFIG=recipes/Qwen2.5-1.5B-Instruct/best_of_n.yaml
uv run python scripts/test_time_compute.py $CONFIG
```

ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ MATH-500ì˜ ì²« 10ë¬¸ì œì— Best-of-N(`n=4`)ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ `data/`ì— ì €ì¥í•©ë‹ˆë‹¤.

ì»¤ë§¨ë“œë¼ì¸ìœ¼ë¡œ ì„¤ì •ì„ ì˜¤ë²„ë¼ì´ë“œ:

```shell
uv run python scripts/test_time_compute.py $CONFIG \
    --model_path=meta-llama/Llama-3.2-8B-Instruct \
    --prm_path=Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B \
    --dataset_name=AI-MO/aimo-validation-aime \
    --dataset_split=train \
    --n=64 \
    --seed=42
```

> **ì°¸ê³ :** ê¸°ë³¸ configëŠ” Llama 3 ìˆ˜í•™ ì¶”ë¡  ìµœì í™” ì±„íŒ… í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ ê³„ì—´ì€ `--custom_chat_template=none` ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## ì˜¨ë„ ì‹¤í—˜

### ë‹¨ì¼ ì˜¨ë„ ì‹¤í—˜

```shell
# ì €ì˜¨ (ì§‘ì¤‘ íƒìƒ‰)
uv run python scripts/test_time_compute.py $CONFIG --temperature=0.4

# ê³ ì˜¨ (ë‹¤ì–‘ì„± íƒìƒ‰)
uv run python scripts/test_time_compute.py $CONFIG --temperature=1.2
```

### ë©€í‹° ì˜¨ë„ ìƒ˜í”Œë§

íƒìƒ‰ ì˜ˆì‚° Nì„ ì—¬ëŸ¬ ì˜¨ë„ì— ë¶„ë°°í•˜ì—¬ íƒìƒ‰ ë‹¤ì–‘ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤:

```shell
# Best-of-N: ì˜¨ë„ë³„ ë¹„ìœ¨ë¡œ n ë¶„ë°°
uv run python scripts/test_time_compute.py $CONFIG \
    --temperatures "0.4,0.8,1.2" \
    --temperature_ratios "0.33,0.34,0.33" \
    --n 12

# Beam Search / DVTS: ê° ë¹”ì´ ì˜¨ë„ ëª©ë¡ì„ ìˆœí™˜
uv run python scripts/test_time_compute.py $CONFIG \
    --approach beam_search \
    --temperatures "0.4,0.8,1.2" \
    --beam_width 3 --n 12
```

ì„¤ì • ì œì•½: `n`ì€ ì˜¨ë„ ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì ¸ì•¼ í•˜ë©°, beam_search/dvtsì˜ ê²½ìš° `beam_width`ë¡œë„ ë‚˜ëˆ„ì–´ ë–¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤. ì „ì²´ ê°€ì´ë“œëŠ” [`TEST_GUIDE.md`](TEST_GUIDE.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### Hot/Cold ë¹„êµ ì‹¤í—˜ (í•µì‹¬ ì‹¤í—˜)

```shell
# ì „ì²´ ì˜¨ë„ ìŠ¤í™íŠ¸ëŸ¼ì— ëŒ€í•œ ëŒ€ê·œëª¨ ì‹¤í—˜ ì œì¶œ
./run_hnc.sh
```

`run_hnc.sh`ëŠ” ì €ì˜¨(cold)ê³¼ ê³ ì˜¨(hot) ì¡°ê±´ì„ í¬í•¨í•œ ì‹¤í—˜ ë°°ì¹˜ë¥¼ Slurm ì–´ë ˆì´ ì¡ìœ¼ë¡œ ì œì¶œí•©ë‹ˆë‹¤.

---

## ì§€ì› ëª¨ë¸ ë° PRM

**ìƒì„± ëª¨ë¸:**

| ëª¨ë¸ | ì œê³µ ë ˆì‹œí”¼ |
| :--- | :--- |
| `Qwen/Qwen2.5-3B-Instruct` | best_of_n, beam_search, dvts |
| `Qwen/Qwen2.5-1.5B-Instruct` | best_of_n, beam_search, dvts |
| `meta-llama/Llama-3.2-3B-Instruct` | best_of_n, beam_search, dvts |
| `meta-llama/Llama-3.2-1B-Instruct` | best_of_n, beam_search, dvts |
| `nvidia/AceMath-7B-Instruct` | best_of_n, beam_search, dvts |

í˜¸í™˜ ì±„íŒ… í…œí”Œë¦¿ì„ ê°€ì§„ ëª¨ë“  ëª¨ë¸ì€ `--model_path`ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

**Process Reward Models:**

- `RLHFlow/Llama3.1-8B-PRM-Deepseek-Data` (ê¸°ë³¸ê°’)
- `peiyi9979/math-shepherd-mistral-7b-prm`
- `Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B`
- `Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B`
- TRLë¡œ ì§ì ‘ í›ˆë ¨í•œ PRM (see [`recipes/training/`](recipes/training/))

---

## ëŒ€ê·œëª¨ ì‹¤í—˜

500ë¬¸ì œ, `n=256`, ë‹¤ì¤‘ ì‹œë“œ/ì˜¨ë„ ì¡°ê±´ì˜ ì „ì²´ ì‹¤í—˜ì€ ë³‘ë ¬í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### ë³‘ë ¬ ìƒì„±

```shell
# ë°ì´í„°ì…‹ì„ ë¶„í• í•˜ì—¬ ì–´ë ˆì´ ì¡ ì œì¶œ
sbatch recipes/launch_array_default.slurm recipes/Qwen2.5-3B-Instruct/best_of_n.yaml \
    --n=256 --seed=0 \
    --hub_dataset_id=<YOUR_ORG>/Qwen2.5-3B-best_of_n-completions

# ì „ì²´ ì™„ë£Œ í›„ ê²°ê³¼ ë³‘í•©
python scripts/merge_chunks.py \
    --dataset_name=<YOUR_ORG>/Qwen2.5-3B-best_of_n-completions \
    --filter_strings seed-0
```

### ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```shell
./run_default.sh                               # ê¸°ë³¸ ì‹¤í—˜ ì¡ ì „ì²´ ì œì¶œ
./run_hnc.sh                                   # Hot/Cold ì˜¨ë„ ì‹¤í—˜ ì œì¶œ
./merge_default.sh                             # ì™„ë£Œëœ ë³‘ë ¬ ê²°ê³¼ ë³‘í•©
python scripts/run_missing_auto.py --dry-run   # ëˆ„ë½ ë²”ìœ„ íƒì§€ ë° ì œì¶œ
```

---

## PRM í›ˆë ¨

TRLë¡œ ì§ì ‘ PRMì„ íŒŒì¸íŠœë‹:

```shell
pip install -e '.[trl]'
# recipes/training/ ì˜ ëª¨ë¸ë³„ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ì°¸ê³ 
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
â”œâ”€â”€ src/sal/               # í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”œâ”€â”€ config.py          # ì¤‘ì•™ Config ë°ì´í„°í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ models/            # PRM ë¡œë”© ë° ì¶”ë¡ 
â”‚   â”œâ”€â”€ search/            # best_of_n, beam_search, dvts ì•Œê³ ë¦¬ì¦˜
â”‚   â””â”€â”€ utils/             # ë°ì´í„° ë¡œë”©, ìŠ¤ì½”ì–´ë§, ì˜¨ë„ ìŠ¤ì¼€ì¤„ë§
â”œâ”€â”€ scripts/               # ì‹¤í—˜ ì§„ì…ì  ë° ìë™í™”
â”‚   â”œâ”€â”€ test_time_compute.py   # ë©”ì¸ ì‹¤í—˜ ëŸ¬ë„ˆ
â”‚   â”œâ”€â”€ merge_chunks.py        # ë³‘ë ¬ ì¡ ê²°ê³¼ ë³‘í•©
â”‚   â””â”€â”€ run_missing_auto.py    # ëˆ„ë½ ì¡ ìë™ íƒì§€/ì œì¶œ
â”œâ”€â”€ recipes/               # ëª¨ë¸/ì•Œê³ ë¦¬ì¦˜ë³„ YAML ì„¤ì • + Slurm ëŸ°ì²˜
â”œâ”€â”€ prm-toolkit/           # PRM ì„œë²„ ì¸í”„ë¼ (git ì„œë¸Œëª¨ë“ˆ)
â””â”€â”€ TEST_GUIDE.md          # ë©€í‹° ì˜¨ë„ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ
```

---

## Citation

```bibtex
@misc{beeching2024scalingtesttimecompute,
      title={Scaling test-time compute with open models},
      author={Edward Beeching and Lewis Tunstall and Sasha Rush},
      url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
}
```

```bibtex
@misc{snell2024scalingllmtesttimecompute,
      title={Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters},
      author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
      year={2024},
      eprint={2408.03314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.03314},
}
```
